{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIMAT0005905</th>\n",
       "      <th>MIMAT0027511</th>\n",
       "      <th>MIMAT0007888</th>\n",
       "      <th>MIMAT0022260</th>\n",
       "      <th>MIMAT0027540</th>\n",
       "      <th>MIMAT0030996</th>\n",
       "      <th>MIMAT0004602</th>\n",
       "      <th>MIMAT0015058</th>\n",
       "      <th>MIMAT0027600</th>\n",
       "      <th>MIMAT0027532</th>\n",
       "      <th>...</th>\n",
       "      <th>MIMAT0019710</th>\n",
       "      <th>MIMAT0004982</th>\n",
       "      <th>MIMAT0005586</th>\n",
       "      <th>MIMAT0016904</th>\n",
       "      <th>MIMAT0027462</th>\n",
       "      <th>MIMAT0016878</th>\n",
       "      <th>MIMAT0018925</th>\n",
       "      <th>MIMAT0003308</th>\n",
       "      <th>MIMAT0019069</th>\n",
       "      <th>MIMAT0027678</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.019922</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>0.010143</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.042740</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.015720</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.013204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075193</td>\n",
       "      <td>0.089498</td>\n",
       "      <td>0.136878</td>\n",
       "      <td>0.083678</td>\n",
       "      <td>0.021734</td>\n",
       "      <td>0.066832</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.071388</td>\n",
       "      <td>0.082758</td>\n",
       "      <td>0.109904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079054</td>\n",
       "      <td>0.078381</td>\n",
       "      <td>0.047978</td>\n",
       "      <td>0.125223</td>\n",
       "      <td>0.053755</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.037504</td>\n",
       "      <td>0.067263</td>\n",
       "      <td>0.054603</td>\n",
       "      <td>0.079024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006139</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.019226</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>0.021443</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.004096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033216</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>0.046828</td>\n",
       "      <td>0.018303</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>0.014849</td>\n",
       "      <td>0.060351</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.020720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.009566</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.013923</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.003049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>0.147351</td>\n",
       "      <td>0.123930</td>\n",
       "      <td>0.135164</td>\n",
       "      <td>0.089130</td>\n",
       "      <td>0.055763</td>\n",
       "      <td>0.168694</td>\n",
       "      <td>0.014374</td>\n",
       "      <td>0.178111</td>\n",
       "      <td>0.182369</td>\n",
       "      <td>0.153661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064729</td>\n",
       "      <td>0.068356</td>\n",
       "      <td>0.080792</td>\n",
       "      <td>0.110381</td>\n",
       "      <td>0.142279</td>\n",
       "      <td>0.143024</td>\n",
       "      <td>0.071135</td>\n",
       "      <td>0.165441</td>\n",
       "      <td>0.062410</td>\n",
       "      <td>0.165898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>0.023960</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.004798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>0.041477</td>\n",
       "      <td>0.070236</td>\n",
       "      <td>0.084824</td>\n",
       "      <td>0.049999</td>\n",
       "      <td>0.035269</td>\n",
       "      <td>0.054830</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.079357</td>\n",
       "      <td>0.076277</td>\n",
       "      <td>0.073453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.041044</td>\n",
       "      <td>0.034045</td>\n",
       "      <td>0.036547</td>\n",
       "      <td>0.048062</td>\n",
       "      <td>0.058674</td>\n",
       "      <td>0.032161</td>\n",
       "      <td>0.067382</td>\n",
       "      <td>0.027107</td>\n",
       "      <td>0.069371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>0.018048</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>0.009107</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.009126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.019922</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>0.010143</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.042740</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.015720</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.013204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MIMAT0005905  MIMAT0027511  MIMAT0007888  MIMAT0022260  MIMAT0027540  \\\n",
       "0         0.025316      0.021317      0.027344      0.019922      0.008474   \n",
       "1         0.075193      0.089498      0.136878      0.083678      0.021734   \n",
       "2         0.006139      0.009533      0.011401      0.004260      0.000625   \n",
       "3         0.033216      0.018407      0.046828      0.018303      0.004018   \n",
       "4         0.014604      0.008284      0.023791      0.010526      0.004860   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1174      0.147351      0.123930      0.135164      0.089130      0.055763   \n",
       "1175      0.014856      0.008702      0.023960      0.003433      0.000403   \n",
       "1176      0.041477      0.070236      0.084824      0.049999      0.035269   \n",
       "1177      0.018048      0.006942      0.012514      0.007716      0.004662   \n",
       "1178      0.025316      0.021317      0.027344      0.019922      0.008474   \n",
       "\n",
       "      MIMAT0030996  MIMAT0004602  MIMAT0015058  MIMAT0027600  MIMAT0027532  \\\n",
       "0         0.010143      0.000332      0.015625      0.015166      0.013157   \n",
       "1         0.066832      0.010150      0.071388      0.082758      0.109904   \n",
       "2         0.019226      0.000550      0.010015      0.017116      0.010986   \n",
       "3         0.003274      0.002766      0.007870      0.004571      0.008177   \n",
       "4         0.011179      0.000943      0.007611      0.011185      0.006949   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1174      0.168694      0.014374      0.178111      0.182369      0.153661   \n",
       "1175      0.006565      0.000474      0.006623      0.005207      0.006774   \n",
       "1176      0.054830      0.001988      0.079357      0.076277      0.073453   \n",
       "1177      0.006875      0.000521      0.009413      0.009107      0.008881   \n",
       "1178      0.010143      0.000332      0.015625      0.015166      0.013157   \n",
       "\n",
       "      ...  MIMAT0019710  MIMAT0004982  MIMAT0005586  MIMAT0016904  \\\n",
       "0     ...      0.008960      0.013301      0.008901      0.025350   \n",
       "1     ...      0.079054      0.078381      0.047978      0.125223   \n",
       "2     ...      0.008390      0.003143      0.011893      0.021443   \n",
       "3     ...      0.027429      0.013410      0.014849      0.060351   \n",
       "4     ...      0.011462      0.007555      0.009566      0.029653   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "1174  ...      0.064729      0.068356      0.080792      0.110381   \n",
       "1175  ...      0.000000      0.006128      0.001842      0.002690   \n",
       "1176  ...      0.015358      0.041044      0.034045      0.036547   \n",
       "1177  ...      0.003613      0.008328      0.001196      0.010945   \n",
       "1178  ...      0.008960      0.013301      0.008901      0.025350   \n",
       "\n",
       "      MIMAT0027462  MIMAT0016878  MIMAT0018925  MIMAT0003308  MIMAT0019069  \\\n",
       "0         0.011162      0.042740      0.009998      0.015720      0.005291   \n",
       "1         0.053755      0.092271      0.037504      0.067263      0.054603   \n",
       "2         0.004858      0.006881      0.002657      0.022649      0.001915   \n",
       "3         0.002592      0.031233      0.003155      0.001976      0.003029   \n",
       "4         0.004204      0.013923      0.003179      0.010850      0.001443   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1174      0.142279      0.143024      0.071135      0.165441      0.062410   \n",
       "1175      0.002709      0.011083      0.003887      0.002965      0.003748   \n",
       "1176      0.048062      0.058674      0.032161      0.067382      0.027107   \n",
       "1177      0.007547      0.015693      0.004723      0.006290      0.004376   \n",
       "1178      0.011162      0.042740      0.009998      0.015720      0.005291   \n",
       "\n",
       "      MIMAT0027678  \n",
       "0         0.013204  \n",
       "1         0.079024  \n",
       "2         0.004096  \n",
       "3         0.020720  \n",
       "4         0.003049  \n",
       "...            ...  \n",
       "1174      0.165898  \n",
       "1175      0.004798  \n",
       "1176      0.069371  \n",
       "1177      0.009126  \n",
       "1178      0.013204  \n",
       "\n",
       "[1179 rows x 45 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"./GEO Samples/dimension_reduced_data.csv\"\n",
    "x = pd.read_csv(filepath)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MIMAT0005905', 'MIMAT0027511', 'MIMAT0007888', 'MIMAT0022260',\n",
       "       'MIMAT0027540', 'MIMAT0030996', 'MIMAT0004602', 'MIMAT0015058',\n",
       "       'MIMAT0027600', 'MIMAT0027532', 'MIMAT0027496', 'MIMAT0030420',\n",
       "       'MIMAT0019871', 'MIMAT0005582', 'MIMAT0018205', 'MIMAT0027444',\n",
       "       'MIMAT0028117', 'MIMAT0004951', 'MIMAT0019956', 'MIMAT0003240',\n",
       "       'MIMAT0027423', 'MIMAT0015080', 'MIMAT0019852', 'MIMAT0027452',\n",
       "       'MIMAT0016900', 'MIMAT0021082', 'MIMAT0005922', 'MIMAT0015064',\n",
       "       'MIMAT0027365', 'MIMAT0005866', 'MIMAT0019229', 'MIMAT0026477',\n",
       "       'MIMAT0027550', 'MIMAT0019015', 'MIMAT0019870', 'MIMAT0019710',\n",
       "       'MIMAT0004982', 'MIMAT0005586', 'MIMAT0016904', 'MIMAT0027462',\n",
       "       'MIMAT0016878', 'MIMAT0018925', 'MIMAT0003308', 'MIMAT0019069',\n",
       "       'MIMAT0027678'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Stage\n",
       "0         2\n",
       "1         0\n",
       "2         4\n",
       "3         2\n",
       "4         2\n",
       "...     ...\n",
       "1174      0\n",
       "1175      4\n",
       "1176      4\n",
       "1177      2\n",
       "1178      2\n",
       "\n",
       "[1179 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"./GEO Samples/dimension_reduced_data_lables.csv\"\n",
    "y = pd.read_csv(filepath)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y[\"Stage\"], test_size=0.2, stratify=y[\"Stage\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",     # for multi-class classification\n",
    "    num_class=5,                   # number of classes (0–4)\n",
    "    eval_metric=\"mlogloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=1,           # class balancing (advanced tuning later)\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aisa\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:36:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for Cancerours and non-cancerouse data (Stage 0 -4) \n",
      " -------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        48\n",
      "           1       0.74      0.69      0.72        42\n",
      "           2       0.96      1.00      0.98        46\n",
      "           3       0.79      0.79      0.79        53\n",
      "           4       0.96      1.00      0.98        47\n",
      "\n",
      "    accuracy                           0.89       236\n",
      "   macro avg       0.89      0.89      0.89       236\n",
      "weighted avg       0.89      0.89      0.89       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification for Cancerours and non-cancerouse data (Stage 0 -4) \\n -------------------------------------------\")\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
