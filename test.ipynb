{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211db0d3-bbc4-4d1d-b67b-d2bac0b04db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc579616-515b-4ffd-8b77-317120331393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__class__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__enter__\n",
      "__eq__\n",
      "__exit__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__getstate__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__sizeof__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "_encode\n",
      "_get_file_writer\n",
      "add_audio\n",
      "add_custom_scalars\n",
      "add_custom_scalars_marginchart\n",
      "add_custom_scalars_multilinechart\n",
      "add_embedding\n",
      "add_figure\n",
      "add_graph\n",
      "add_histogram\n",
      "add_histogram_raw\n",
      "add_hparams\n",
      "add_image\n",
      "add_image_with_boxes\n",
      "add_images\n",
      "add_mesh\n",
      "add_onnx_graph\n",
      "add_pr_curve\n",
      "add_pr_curve_raw\n",
      "add_scalar\n",
      "add_scalars\n",
      "add_tensor\n",
      "add_text\n",
      "add_video\n",
      "all_writers\n",
      "close\n",
      "default_bins\n",
      "file_writer\n",
      "filename_suffix\n",
      "flush\n",
      "flush_secs\n",
      "get_logdir\n",
      "log_dir\n",
      "max_queue\n",
      "purge_step\n"
     ]
    }
   ],
   "source": [
    "for x in dir(tensorboard_writer):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "191429d0-d0ee-49d8-96cf-cf8253761891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Step [100/10000], Loss: 2.2062, Acc: 0.37\n",
      "Step [200/10000], Loss: 2.1217, Acc: 0.67\n",
      "Step [300/10000], Loss: 2.0138, Acc: 0.73\n",
      "Step [400/10000], Loss: 1.8891, Acc: 0.77\n",
      "Step [500/10000], Loss: 1.7238, Acc: 0.72\n",
      "Step [600/10000], Loss: 1.6126, Acc: 0.78\n",
      "Step [700/10000], Loss: 1.5203, Acc: 0.79\n",
      "Step [800/10000], Loss: 1.2958, Acc: 0.85\n",
      "Step [900/10000], Loss: 1.2720, Acc: 0.82\n",
      "Step [1000/10000], Loss: 1.1158, Acc: 0.78\n",
      "Step [1100/10000], Loss: 1.1818, Acc: 0.79\n",
      "Step [1200/10000], Loss: 1.0087, Acc: 0.83\n",
      "Step [1300/10000], Loss: 0.9469, Acc: 0.82\n",
      "Step [1400/10000], Loss: 1.0247, Acc: 0.78\n",
      "Step [1500/10000], Loss: 0.7590, Acc: 0.92\n",
      "Step [1600/10000], Loss: 0.7971, Acc: 0.83\n",
      "Step [1700/10000], Loss: 0.8470, Acc: 0.83\n",
      "Step [1800/10000], Loss: 0.7787, Acc: 0.83\n",
      "Step [1900/10000], Loss: 0.7213, Acc: 0.87\n",
      "Step [2000/10000], Loss: 0.5879, Acc: 0.90\n",
      "Step [2100/10000], Loss: 0.7075, Acc: 0.86\n",
      "Step [2200/10000], Loss: 0.5931, Acc: 0.92\n",
      "Step [2300/10000], Loss: 0.7022, Acc: 0.84\n",
      "Step [2400/10000], Loss: 0.6311, Acc: 0.86\n",
      "Step [2500/10000], Loss: 0.5349, Acc: 0.88\n",
      "Step [2600/10000], Loss: 0.5111, Acc: 0.87\n",
      "Step [2700/10000], Loss: 0.5643, Acc: 0.88\n",
      "Step [2800/10000], Loss: 0.5117, Acc: 0.85\n",
      "Step [2900/10000], Loss: 0.5851, Acc: 0.85\n",
      "Step [3000/10000], Loss: 0.5072, Acc: 0.86\n",
      "Step [3100/10000], Loss: 0.4610, Acc: 0.86\n",
      "Step [3200/10000], Loss: 0.5182, Acc: 0.89\n",
      "Step [3300/10000], Loss: 0.3922, Acc: 0.92\n",
      "Step [3400/10000], Loss: 0.5682, Acc: 0.86\n",
      "Step [3500/10000], Loss: 0.4986, Acc: 0.91\n",
      "Step [3600/10000], Loss: 0.5373, Acc: 0.87\n",
      "Step [3700/10000], Loss: 0.3949, Acc: 0.93\n",
      "Step [3800/10000], Loss: 0.5169, Acc: 0.86\n",
      "Step [3900/10000], Loss: 0.5637, Acc: 0.87\n",
      "Step [4000/10000], Loss: 0.4878, Acc: 0.89\n",
      "Step [4100/10000], Loss: 0.4574, Acc: 0.85\n",
      "Step [4200/10000], Loss: 0.5271, Acc: 0.83\n",
      "Step [4300/10000], Loss: 0.4085, Acc: 0.88\n",
      "Step [4400/10000], Loss: 0.3155, Acc: 0.95\n",
      "Step [4500/10000], Loss: 0.4017, Acc: 0.90\n",
      "Step [4600/10000], Loss: 0.3998, Acc: 0.89\n",
      "Step [4700/10000], Loss: 0.3240, Acc: 0.95\n",
      "Step [4800/10000], Loss: 0.3283, Acc: 0.90\n",
      "Step [4900/10000], Loss: 0.3022, Acc: 0.94\n",
      "Step [5000/10000], Loss: 0.3692, Acc: 0.87\n",
      "Step [5100/10000], Loss: 0.3861, Acc: 0.91\n",
      "Step [5200/10000], Loss: 0.3511, Acc: 0.91\n",
      "Step [5300/10000], Loss: 0.4853, Acc: 0.86\n",
      "Step [5400/10000], Loss: 0.2729, Acc: 0.92\n",
      "Step [5500/10000], Loss: 0.4015, Acc: 0.84\n",
      "Step [5600/10000], Loss: 0.3718, Acc: 0.94\n",
      "Step [5700/10000], Loss: 0.3396, Acc: 0.89\n",
      "Step [5800/10000], Loss: 0.4351, Acc: 0.91\n",
      "Step [5900/10000], Loss: 0.4312, Acc: 0.88\n",
      "Step [6000/10000], Loss: 0.2480, Acc: 0.92\n",
      "Step [6100/10000], Loss: 0.2485, Acc: 0.97\n",
      "Step [6200/10000], Loss: 0.4516, Acc: 0.86\n",
      "Step [6300/10000], Loss: 0.2807, Acc: 0.94\n",
      "Step [6400/10000], Loss: 0.2928, Acc: 0.90\n",
      "Step [6500/10000], Loss: 0.3450, Acc: 0.91\n",
      "Step [6600/10000], Loss: 0.4079, Acc: 0.90\n",
      "Step [6700/10000], Loss: 0.2788, Acc: 0.95\n",
      "Step [6800/10000], Loss: 0.3195, Acc: 0.90\n",
      "Step [6900/10000], Loss: 0.3035, Acc: 0.93\n",
      "Step [7000/10000], Loss: 0.3605, Acc: 0.93\n",
      "Step [7100/10000], Loss: 0.4854, Acc: 0.89\n",
      "Step [7200/10000], Loss: 0.3458, Acc: 0.87\n",
      "Step [7300/10000], Loss: 0.3426, Acc: 0.89\n",
      "Step [7400/10000], Loss: 0.3263, Acc: 0.94\n",
      "Step [7500/10000], Loss: 0.3740, Acc: 0.87\n",
      "Step [7600/10000], Loss: 0.2562, Acc: 0.93\n",
      "Step [7700/10000], Loss: 0.2589, Acc: 0.93\n",
      "Step [7800/10000], Loss: 0.2014, Acc: 0.94\n",
      "Step [7900/10000], Loss: 0.3276, Acc: 0.92\n",
      "Step [8000/10000], Loss: 0.3724, Acc: 0.88\n",
      "Step [8100/10000], Loss: 0.2983, Acc: 0.94\n",
      "Step [8200/10000], Loss: 0.2562, Acc: 0.90\n",
      "Step [8300/10000], Loss: 0.3914, Acc: 0.88\n",
      "Step [8400/10000], Loss: 0.3369, Acc: 0.92\n",
      "Step [8500/10000], Loss: 0.2543, Acc: 0.93\n",
      "Step [8600/10000], Loss: 0.2461, Acc: 0.94\n",
      "Step [8700/10000], Loss: 0.5105, Acc: 0.85\n",
      "Step [8800/10000], Loss: 0.2832, Acc: 0.95\n",
      "Step [8900/10000], Loss: 0.4073, Acc: 0.88\n",
      "Step [9000/10000], Loss: 0.2879, Acc: 0.92\n",
      "Step [9100/10000], Loss: 0.4024, Acc: 0.90\n",
      "Step [9200/10000], Loss: 0.2118, Acc: 0.96\n",
      "Step [9300/10000], Loss: 0.4457, Acc: 0.90\n",
      "Step [9400/10000], Loss: 0.3306, Acc: 0.93\n",
      "Step [9500/10000], Loss: 0.4199, Acc: 0.87\n",
      "Step [9600/10000], Loss: 0.1939, Acc: 0.95\n",
      "Step [9700/10000], Loss: 0.3236, Acc: 0.93\n",
      "Step [9800/10000], Loss: 0.2752, Acc: 0.94\n",
      "Step [9900/10000], Loss: 0.3709, Acc: 0.91\n",
      "Step [10000/10000], Loss: 0.3504, Acc: 0.86\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "batch_size = 100\n",
    "total_step = 10000\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# MNIST dataset \n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='../../data', \n",
    "    train=True, \n",
    "    transform=transforms.ToTensor(),  \n",
    "    download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet().to(device)\n",
    "tensorboard_writer = SummaryWriter(\"logs\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  \n",
    "#from torch.utils.data.dataloader.DataLoader to torch.utils.data.dataloader._DataLoaderIter\n",
    "data_iter = iter(data_loader) \n",
    "iter_per_epoch = len(data_loader)\n",
    "# Start training\n",
    "for step in range(total_step):\n",
    "    \n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch images and labels\n",
    "    images, labels = next(data_iter) #only when data_loader is converted to data_iter can \"next\" be used\n",
    "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute accuracy\n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    #torch.squeeze: Returns a tensor with all the dimensions of :attr:`input` of size `1` removed.\n",
    "    #.float() : equals to self.to(torch.float32), if without it:\n",
    "    # get RuntimeError: Can only calculate the mean of floating types. Got Byte instead.\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
    "               .format(step+1, total_step, loss.item(), accuracy.item()))\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                        Tensorboard Logging                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 1. Log scalar values (scalar summary)\n",
    "        info = {\n",
    "            'loss': loss.item(),\n",
    "            'accuracy': accuracy.item()\n",
    "        }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            # scalar_summary(self, tag, value, step): Log a scalar variable.\n",
    "            tensorboard_writer.add_scalar(tag, value, step+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1de1c5-d0b9-4fea-a42f-7c8278abb099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
