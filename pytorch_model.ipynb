{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2997e643-7961-403a-a730-e79fed92e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import MultiStepLR \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca77da7b-6d1b-4bb6-8c59-957fdefb193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data.get_1060_normalized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67cff433-c220-4b5b-a561-35848640979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= X_Train ======\n",
      "torch.Size([1060, 2550])\n",
      "x.min()=tensor(-2.8571)\n",
      "x.max()=tensor(91.7090)\n",
      "x.mean()=tensor(0.0722)\n",
      "x.std()=tensor(0.9352)\n",
      "======= X_Test ======\n",
      "torch.Size([140, 2550])\n",
      "x.min()=tensor(-2.6429)\n",
      "x.max()=tensor(63.7779)\n",
      "x.mean()=tensor(-0.0114)\n",
      "x.std()=tensor(0.8815)\n",
      "======= Y_Train ======\n",
      "torch.Size([1060])\n",
      "x.min()=tensor(0)\n",
      "x.max()=tensor(3)\n",
      "Unique values: tensor([0, 1, 2, 3])\n",
      "Counts: tensor([265, 265, 265, 265])\n",
      "======= Y_Test ======\n",
      "torch.Size([140])\n",
      "x.min()=tensor(0)\n",
      "x.max()=tensor(3)\n",
      "Unique values: tensor([0, 1, 2, 3])\n",
      "Counts: tensor([53, 14, 66,  7])\n"
     ]
    }
   ],
   "source": [
    "# Convert to float32 and torch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "# Convert y from [1, 2, 3, 4] â†’ [0, 1, 2, 3]\n",
    "y_train_tensor = torch.tensor(y_train.values - 1, dtype=torch.long).squeeze()\n",
    "y_test_tensor = torch.tensor(y_test.values - 1, dtype=torch.long).squeeze()\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def print_stat(x, name):\n",
    "    print(f\"======= {name} ======\")\n",
    "    print(x.shape)\n",
    "    print(f\"{x.min()=}\")\n",
    "    print(f\"{x.max()=}\")\n",
    "    if x.dtype == torch.float32:\n",
    "        print(f\"{x.mean()=}\")\n",
    "        print(f\"{x.std()=}\")\n",
    "    if name.lower().startswith(\"y_\"):\n",
    "        unique_values, counts = torch.unique(x, return_counts=True)\n",
    "        print(\"Unique values:\", unique_values)\n",
    "        print(\"Counts:\", counts)\n",
    "\n",
    "print_stat(X_train_tensor, \"X_Train\")\n",
    "print_stat(X_test_tensor, \"X_Test\")\n",
    "print_stat(y_train_tensor, \"Y_Train\")\n",
    "print_stat(y_test_tensor, \"Y_Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76a29be3-3d2f-4185-a1b9-6afeea2f85a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2550"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 4\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 2000\n",
    "LEARNING_RATE = 0.001\n",
    "features_count = X_train.shape[1]\n",
    "features_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36677903-95b7-4951-bebd-a3e987a68f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer = Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "loss_function = CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "class CustomNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(features_count, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 50),\n",
    "            nn.ReLU(),            \n",
    "            nn.Linear(50, 4)  # 4 output classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = CustomNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[100, 400, 800, 1500], gamma=0.1)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"{optimizer = }\")\n",
    "print(f\"{loss_function = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85c74d23-c3e8-4108-b881-a8c0fb8ba65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, loader):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            outputs = model(X_batch)\n",
    "            _, output = torch.max(outputs, 1)\n",
    "            preds.extend(output.numpy())\n",
    "            labels.extend(y_batch.numpy())\n",
    "\n",
    "    return accuracy_score(labels, preds) \n",
    "    # print(\"Training Accuracy:\", accuracy_score(train_labels, train_preds))\n",
    "    # print(\"Classification Report (Train):\\n\", classification_report(train_labels, train_preds))\n",
    "    # print(\"Confusion Matrix (Train):\\n\", confusion_matrix(train_labels, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6e5144b-a404-4775-8819-f3067fdf9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Loss: 44.2438, Train_Acc = 0.5462, Test_Acc = 0.3071\n",
      "Epoch 11/2000, Loss: 7.4880, Train_Acc = 0.9292, Test_Acc = 0.6786\n",
      "Epoch 21/2000, Loss: 2.9444, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 31/2000, Loss: 4.2385, Train_Acc = 0.9708, Test_Acc = 0.7500\n",
      "Epoch 41/2000, Loss: 3.2246, Train_Acc = 0.9811, Test_Acc = 0.8214\n",
      "Epoch 51/2000, Loss: 5.4862, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 61/2000, Loss: 2.1015, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 71/2000, Loss: 2.0655, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 81/2000, Loss: 2.0177, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 91/2000, Loss: 3.1595, Train_Acc = 0.9585, Test_Acc = 0.7786\n",
      "Epoch 101/2000, Loss: 1.9894, Train_Acc = 0.9811, Test_Acc = 0.7857\n",
      "Epoch 111/2000, Loss: 1.7584, Train_Acc = 0.9811, Test_Acc = 0.7857\n",
      "Epoch 121/2000, Loss: 1.7258, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 131/2000, Loss: 1.7221, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 141/2000, Loss: 1.6986, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 151/2000, Loss: 1.6595, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 161/2000, Loss: 1.6743, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 171/2000, Loss: 1.6810, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 181/2000, Loss: 1.6928, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 191/2000, Loss: 2.3155, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 201/2000, Loss: 1.6236, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 211/2000, Loss: 1.6531, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 221/2000, Loss: 1.6446, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 231/2000, Loss: 1.6376, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 241/2000, Loss: 1.6192, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 251/2000, Loss: 1.6351, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 261/2000, Loss: 1.5819, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 271/2000, Loss: 1.6045, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 281/2000, Loss: 1.5985, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 291/2000, Loss: 1.5631, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 301/2000, Loss: 1.5408, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 311/2000, Loss: 1.5662, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 321/2000, Loss: 1.5979, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 331/2000, Loss: 1.5439, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 341/2000, Loss: 1.5263, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 351/2000, Loss: 1.5421, Train_Acc = 0.9811, Test_Acc = 0.8071\n",
      "Epoch 361/2000, Loss: 1.6269, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 371/2000, Loss: 1.5915, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 381/2000, Loss: 1.5362, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 391/2000, Loss: 1.5369, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 401/2000, Loss: 1.4204, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 411/2000, Loss: 1.4394, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 421/2000, Loss: 1.4219, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 431/2000, Loss: 1.4181, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 441/2000, Loss: 1.4242, Train_Acc = 0.9811, Test_Acc = 0.7929\n",
      "Epoch 451/2000, Loss: 1.4136, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 461/2000, Loss: 1.3976, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 471/2000, Loss: 1.4633, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 481/2000, Loss: 1.3961, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 491/2000, Loss: 1.3984, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 501/2000, Loss: 1.3990, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 511/2000, Loss: 1.3977, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 521/2000, Loss: 1.3919, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 531/2000, Loss: 1.4080, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 541/2000, Loss: 1.3932, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 551/2000, Loss: 1.7174, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 561/2000, Loss: 1.4235, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 571/2000, Loss: 1.3922, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 581/2000, Loss: 1.3898, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 591/2000, Loss: 1.3860, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 601/2000, Loss: 1.5592, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 611/2000, Loss: 1.4067, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 621/2000, Loss: 1.3975, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 631/2000, Loss: 1.5431, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 641/2000, Loss: 1.3849, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 651/2000, Loss: 1.5096, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 661/2000, Loss: 1.5033, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 671/2000, Loss: 1.3791, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 681/2000, Loss: 1.3822, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 691/2000, Loss: 1.3765, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 701/2000, Loss: 1.3699, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 711/2000, Loss: 1.7031, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 721/2000, Loss: 1.3974, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 731/2000, Loss: 1.3691, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 741/2000, Loss: 1.3883, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 751/2000, Loss: 1.3673, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 761/2000, Loss: 1.3815, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 771/2000, Loss: 1.3900, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 781/2000, Loss: 1.3665, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 791/2000, Loss: 1.3685, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 801/2000, Loss: 1.3562, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 811/2000, Loss: 1.5141, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 821/2000, Loss: 1.3547, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 831/2000, Loss: 1.3547, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 841/2000, Loss: 1.3541, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 851/2000, Loss: 1.4164, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 861/2000, Loss: 1.3567, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 871/2000, Loss: 1.3975, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 881/2000, Loss: 1.3700, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 891/2000, Loss: 1.3541, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 901/2000, Loss: 1.4614, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 911/2000, Loss: 1.3717, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 921/2000, Loss: 1.3556, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 931/2000, Loss: 1.3603, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 941/2000, Loss: 1.7639, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 951/2000, Loss: 1.3669, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 961/2000, Loss: 1.3619, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 971/2000, Loss: 1.3536, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 981/2000, Loss: 1.3542, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 991/2000, Loss: 1.3569, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1001/2000, Loss: 1.3534, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1011/2000, Loss: 1.3579, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1021/2000, Loss: 1.3532, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1031/2000, Loss: 1.3537, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1041/2000, Loss: 1.3529, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1051/2000, Loss: 1.3526, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1061/2000, Loss: 1.3594, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1071/2000, Loss: 1.3525, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1081/2000, Loss: 1.3526, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1091/2000, Loss: 1.3549, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1101/2000, Loss: 1.3671, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1111/2000, Loss: 1.3982, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1121/2000, Loss: 1.7496, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1131/2000, Loss: 1.3526, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1141/2000, Loss: 1.3526, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1151/2000, Loss: 1.3536, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1161/2000, Loss: 1.3741, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1171/2000, Loss: 1.3533, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1181/2000, Loss: 1.3518, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1191/2000, Loss: 1.4259, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1201/2000, Loss: 1.3558, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1211/2000, Loss: 1.5212, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1221/2000, Loss: 1.3661, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1231/2000, Loss: 1.3512, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1241/2000, Loss: 1.3651, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1251/2000, Loss: 1.7625, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1261/2000, Loss: 1.4812, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1271/2000, Loss: 1.3639, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1281/2000, Loss: 1.3511, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1291/2000, Loss: 1.3516, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1301/2000, Loss: 1.3786, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1311/2000, Loss: 1.3509, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1321/2000, Loss: 1.3510, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1331/2000, Loss: 1.3510, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1341/2000, Loss: 1.3507, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1351/2000, Loss: 1.3539, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1361/2000, Loss: 1.3509, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1371/2000, Loss: 1.3878, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1381/2000, Loss: 1.3587, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1391/2000, Loss: 1.3578, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1401/2000, Loss: 1.4243, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1411/2000, Loss: 1.3561, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1421/2000, Loss: 1.3660, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1431/2000, Loss: 1.3503, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1441/2000, Loss: 1.3546, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1451/2000, Loss: 1.3711, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1461/2000, Loss: 1.3499, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1471/2000, Loss: 1.3843, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1481/2000, Loss: 1.7228, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1491/2000, Loss: 1.3748, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1501/2000, Loss: 1.3937, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1511/2000, Loss: 1.3484, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1521/2000, Loss: 1.4379, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1531/2000, Loss: 1.3763, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1541/2000, Loss: 1.3486, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1551/2000, Loss: 1.3655, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1561/2000, Loss: 1.4068, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1571/2000, Loss: 1.6478, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1581/2000, Loss: 1.3486, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1591/2000, Loss: 1.3944, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1601/2000, Loss: 1.6570, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1611/2000, Loss: 1.4587, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1621/2000, Loss: 1.3483, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1631/2000, Loss: 1.3513, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1641/2000, Loss: 1.3484, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1651/2000, Loss: 1.5395, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1661/2000, Loss: 1.3676, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1671/2000, Loss: 1.3483, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1681/2000, Loss: 1.3919, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1691/2000, Loss: 1.3483, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1701/2000, Loss: 1.3483, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1711/2000, Loss: 1.3482, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1721/2000, Loss: 1.3490, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1731/2000, Loss: 1.3497, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1741/2000, Loss: 1.3485, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1751/2000, Loss: 1.3727, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1761/2000, Loss: 1.5086, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1771/2000, Loss: 1.3482, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1781/2000, Loss: 1.3482, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1791/2000, Loss: 1.3703, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1801/2000, Loss: 1.3482, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1811/2000, Loss: 1.7528, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1821/2000, Loss: 1.3850, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1831/2000, Loss: 1.3481, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1841/2000, Loss: 1.5678, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1851/2000, Loss: 1.3481, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1861/2000, Loss: 1.3481, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1871/2000, Loss: 1.3607, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1881/2000, Loss: 1.5014, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1891/2000, Loss: 1.3521, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1901/2000, Loss: 1.3482, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1911/2000, Loss: 1.3484, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1921/2000, Loss: 1.3481, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1931/2000, Loss: 1.3482, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1941/2000, Loss: 1.3528, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1951/2000, Loss: 1.3566, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1961/2000, Loss: 1.3660, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1971/2000, Loss: 1.3532, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1981/2000, Loss: 1.3495, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Epoch 1991/2000, Loss: 1.3480, Train_Acc = 0.9811, Test_Acc = 0.8000\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "tensorboard_writer = SummaryWriter(\"logs\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = loss_function(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "\n",
    "    info = {\n",
    "        'loss': total_loss,\n",
    "        'lr': scheduler.get_last_lr()[0],\n",
    "    }\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = evaluation(model, train_loader)\n",
    "        test_acc = evaluation(model, test_loader)\n",
    "        info[\"train_accuracy\"] = train_acc\n",
    "        info[\"test_accuracy\"] = test_acc\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss:.4f}, Train_Acc = {train_acc:0.4f}, Test_Acc = {test_acc:0.4f}\")\n",
    "    \n",
    "    for tag, value in info.items():\n",
    "        tensorboard_writer.add_scalar(\"scalars/\" + tag, value, epoch+1)\n",
    "\n",
    "print(\"Training finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56143dd-c147-43d6-b9b4-9006a1bc239c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
